{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "        \n",
    "        # Camera calibration, given object points, image points, and the shape of the grayscale image:\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth...\n",
    "\n",
    "Should now have objpoints and imgpoints needed for camera calibration. Run the cell below to calibrate, calculate distortion coefficients, and test undistortion on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Test undistortion on an image\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('camera_cal/test_undist_' + fname + '.jpg',dst)\n",
    "\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    with open('camera_cal/wide_dist_pickle.pickle', 'wb') as handle:\n",
    "        pickle.dump(dist_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    #dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use color transforms, gradients, etc., to create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "image = mpimg.imread('test_images/test5.jpg')\n",
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "def binary_filter(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    return combined_binary\n",
    "    \n",
    "result = binary_filter(image)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "ax2.imshow(result,cmap='gray')\n",
    "ax2.set_title('Pipeline Result', fontsize=40, )\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "\n",
    "dist_pickle = pickle.load(open( \"camera_cal/wide_dist_pickle.pickle\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def persepctive_transform(img, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result \n",
    "    # again, not exact, but close enough for our purposes\n",
    "    # TODO:\n",
    "    leftupperpoint  = [570,470]\n",
    "    rightupperpoint = [720,470]\n",
    "    leftlowerpoint  = [260,680]\n",
    "    rightlowerpoint = [1050,680]\n",
    "    \n",
    "    src = np.float32([leftupperpoint, leftlowerpoint, rightupperpoint, rightlowerpoint])\n",
    "    dst = np.float32([[200,0], [200,680], [1000,0], [1000,680]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "for fname in images:\n",
    "    image = mpimg.imread(fname)\n",
    "    binary_img = binary_filter(image)\n",
    "    top_down, perspective_M = persepctive_transform(binary_img, mtx, dist)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(top_down,cmap='gray')\n",
    "    ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    \n",
    "    return out_img\n",
    "\n",
    "for fname in images:\n",
    "    image = mpimg.imread(fname)\n",
    "    binary_image = binary_filter(image)\n",
    "    top_down, perspective_M = persepctive_transform(binary_image, mtx, dist)\n",
    "    out_img = fit_polynomial(top_down)\n",
    "    \n",
    "    plt.imshow(out_img)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the curvature of the lane and vehicle position with respect to center.\n",
    "Warp the detected lane boundaries back onto the original image.\n",
    "Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    lane = {}\n",
    "    lane[\"left_fitx\"] = left_fitx\n",
    "    lane[\"ploty\"] = ploty\n",
    "    lane[\"right_fitx\"] = right_fitx\n",
    "\n",
    "    return lane\n",
    "\n",
    "def inv_persepctive_transform(img, mtx, dist):\n",
    "    # TODO:\n",
    "    leftupperpoint  = [570,470]\n",
    "    rightupperpoint = [720,470]\n",
    "    leftlowerpoint  = [260,680]\n",
    "    rightlowerpoint = [1050,680]\n",
    "    \n",
    "    dst = np.float32([leftupperpoint, leftlowerpoint, rightupperpoint, rightlowerpoint])\n",
    "    src = np.float32([[200,0], [200,680], [1000,0], [1000,680]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "def og_img_plot_lanes(image, lane):\n",
    "    image = np.dstack((image, image, image))*255\n",
    "\n",
    "    \n",
    "    top_down_og, perspective_M_og = persepctive_transform(image, mtx, dist)\n",
    "\n",
    "    # draw lane \n",
    "    left_points = np.array(list(zip(lane[\"left_fitx\"], lane[\"ploty\"])), np.int32)\n",
    "    right_points = np.array(list(zip(lane[\"right_fitx\"], lane[\"ploty\"])), np.int32)\n",
    "    \n",
    "    cv2.polylines(top_down_og, [left_points], False, [255, 0, 0], 15)\n",
    "    cv2.polylines(top_down_og, [right_points], False, [255, 0, 0], 15)\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    left_line_window = np.array(np.transpose(np.vstack([lane[\"left_fitx\"], lane[\"ploty\"]])))\n",
    "    right_line_window = np.array(np.flipud(np.transpose(np.vstack([lane[\"right_fitx\"], lane[\"ploty\"]]))))\n",
    "    line_points = np.vstack((left_line_window, right_line_window))\n",
    "\n",
    "    cv2.fillPoly(top_down_og, np.int_([line_points]), [0,255,0])\n",
    "    \n",
    "    inv_warped_img, M = inv_persepctive_transform(top_down_og, mtx, dist)\n",
    "        \n",
    "    return inv_warped_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "for fname in images:\n",
    "    image = mpimg.imread(fname)\n",
    "    \n",
    "    binary_image = binary_filter(image)\n",
    "    \n",
    "    top_down_binary_warped, perspective_M_bin = persepctive_transform(binary_image, mtx, dist)\n",
    "    \n",
    "    lane = fit_polynomial(top_down_binary_warped)\n",
    "    \n",
    "    inv_warped_img = og_img_plot_lanes(binary_image, lane)\n",
    "    \n",
    "    result = weighted_img(inv_warped_img, image, 1.0, 0.3, 0)\n",
    "\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#     f.tight_layout()\n",
    "#     ax1.imshow(image)\n",
    "#     ax1.set_title('Original Image', fontsize=50)\n",
    "#     ax2.imshow(inv_warped_img)\n",
    "#     ax2.set_title('Image With Lanes', fontsize=50)\n",
    "#     plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    \n",
    "# https://docs.opencv.org/2.4/doc/tutorials/core/adding_images/adding_images.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_filter(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel_x = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Sobel y\n",
    "    sobely = cv2.Sobel(l_channel, cv2.CV_64F, 0, 1) # Take the derivative in x\n",
    "    abs_sobely = np.absolute(sobely) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel_y = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel_x)\n",
    "    sxbinary[(scaled_sobel_x >= sx_thresh[0]) & (scaled_sobel_x <= sx_thresh[1])] = 1\n",
    "    \n",
    "#     # Threshold y gradient\n",
    "#     sybinary = np.zeros_like(scaled_sobel_y)\n",
    "#     sybinary[(scaled_sobel_y >= sy_thresh[0]) & (scaled_sobel_y <= sy_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def persepctive_transform(img, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # source points on the image\n",
    "    leftupperpoint  = [570,470]\n",
    "    rightupperpoint = [720,470]\n",
    "    leftlowerpoint  = [260,680]\n",
    "    rightlowerpoint = [1050,680]\n",
    "    \n",
    "    # destination points to transform to\n",
    "    src = np.float32([leftupperpoint, leftlowerpoint, rightupperpoint, rightlowerpoint])\n",
    "    dst = np.float32([[200,0], [200,680], [1000,0], [1000,680]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "def inv_persepctive_transform(img, mtx, dist):\n",
    "    # TODO:\n",
    "    leftupperpoint  = [570,470]\n",
    "    rightupperpoint = [720,470]\n",
    "    leftlowerpoint  = [260,680]\n",
    "    rightlowerpoint = [1050,680]\n",
    "    \n",
    "    dst = np.float32([leftupperpoint, leftlowerpoint, rightupperpoint, rightlowerpoint])\n",
    "    src = np.float32([[200,0], [200,680], [1000,0], [1000,680]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "def og_img_plot_lanes(image, left_lane, right_lane):\n",
    "    image = np.dstack((image, image, image))*255\n",
    "\n",
    "    top_down_og, perspective_M_og = persepctive_transform(image, mtx, dist)\n",
    "\n",
    "    # draw lane \n",
    "    left_points = np.array(list(zip(left_lane.allx, left_lane.ally)), np.int32)\n",
    "    right_points = np.array(list(zip(right_lane.allx, right_lane.ally)), np.int32)\n",
    "    \n",
    "    cv2.polylines(top_down_og, [left_points], False, [255, 0, 0], 15)\n",
    "    cv2.polylines(top_down_og, [right_points], False, [255, 0, 0], 15)\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    left_line_window = np.array(np.transpose(np.vstack([left_lane.allx, left_lane.ally])))\n",
    "    right_line_window = np.array(np.flipud(np.transpose(np.vstack([right_lane.allx, left_lane.ally]))))\n",
    "    line_points = np.vstack((left_line_window, right_line_window))\n",
    "\n",
    "    cv2.fillPoly(top_down_og, np.int_([line_points]), [0,255,0])\n",
    "    \n",
    "    inv_warped_img, M = inv_persepctive_transform(top_down_og, mtx, dist)\n",
    "    \n",
    "    return inv_warped_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "def fit_lane_lines(binary_warped):\n",
    "    # Brutal run-time, need to fix someday. Separate left lane and right lane detection \n",
    "    if left_lane.detected == True and right_lane.detected == True:\n",
    "        leftx, lefty, rightx, righty, out_img = search_around_pixels(binary_warped)\n",
    "        left_lane, right_lane = fit_polynomial(out_img, leftx, lefty, rightx, righty)\n",
    "    else:\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "        left_lane, right_lane = fit_polynomial(out_img, leftx, lefty, rightx, righty)\n",
    "        \n",
    "    fit_flag = sanity_check(left_lane, right_lane)\n",
    "    \n",
    "    # if the new found lane lines are not a good fit, use sliding windows\n",
    "    if fit_flag == False:\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "        left_lane, right_lane = fit_polynomial(out_img, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    return left_lane, right_lane\n",
    "    \n",
    "\n",
    "def fit_polynomial(binary_warped, leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "    \n",
    "    ## Curvature Calculation ##\n",
    "    left_curverad, right_curverad, center_dist = measure_curvature_pixels(binary_warped, ploty, left_fit, right_fit)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    left_lane.best_fit = left_fit\n",
    "    left_lane.allx = left_fitx\n",
    "    left_lane.ally = ploty\n",
    "    right_lane.best_fit = right_fit\n",
    "    right_lane.allx = right_fitx\n",
    "    right_lane.ally = ploty\n",
    "    left_lane.radius_of_curvature = left_curverad\n",
    "    right_lane.radius_of_curvature = right_curverad\n",
    "    left_lane.center_dist = center_dist\n",
    "\n",
    "    return left_lane, right_lane\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def measure_curvature_pixels(binary_warped_img, ploty, left_fit, right_fit):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### Calculation of R_curve (radius of curvature) #####\n",
    "    left_fit_d  = 2*left_fit[0]*y_eval*ym_per_pix + left_fit[1]\n",
    "    left_fit_dd = 2*left_fit[0]\n",
    "    right_fit_d  = 2*right_fit[0]*y_eval*ym_per_pix + right_fit[1]\n",
    "    right_fit_dd = 2*right_fit[0]\n",
    "    \n",
    "    left_curverad = (1 + left_fit_d**2)**(3/2) / np.absolute(left_fit_dd)\n",
    "    right_curverad = (1 + right_fit_d**2)**(3/2) / np.absolute(right_fit_dd)\n",
    "    \n",
    "    ## Calculation of lane center ## \n",
    "    img_height = binary_warped_img.shape[0]\n",
    "    img_width = binary_warped_img.shape[1]\n",
    "    img_center_pos = binary_warped_img.shape[1] / 2\n",
    "    left_fit_x = left_fit[0]*img_height**2 + left_fit[1]*img_height + left_fit[2]\n",
    "    right_fit_x = right_fit[0]*img_height**2 + right_fit[1]*img_height + right_fit[2]\n",
    "    \n",
    "    lane_center_position = (left_fit_x + right_fit_x) /2\n",
    "    center_dist = (img_width - lane_center_position) * xm_per_pix\n",
    "    \n",
    "    return left_curverad, right_curverad, center_dist\n",
    "\n",
    "\n",
    "def display_data(img, left_lane, right_lane):\n",
    "    curve_rad = (left_lane.radius_of_curvature + right_lane.radius_of_curvature ) / 2\n",
    "    center_dist = left_lane.center_dist\n",
    "    \n",
    "    car_dir = ''\n",
    "    \n",
    "    if center_dist > 0:\n",
    "        car_dir = 'right'\n",
    "    elif center_dist < 0:\n",
    "        car_dir = 'left'\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    radius_text = 'Curve radius: ' + '{:04.2f}'.format(curve_rad) + 'm'\n",
    "    center_text = '{:04.3f}'.format(abs(center_dist)) + 'm ' + car_dir + ' of center'\n",
    "    \n",
    "    cv2.putText(img, radius_text, (40,70), font, 1.5, (200,200,150), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, center_text, (40,120), font, 1.5, (200,200,150), 2, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def search_around_poly(binary_warped, left_lane, right_lane):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_fit = left_lane.best_fit \n",
    "    right_fit = right_lane.best_fit \n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_fit_line = left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2]\n",
    "    right_fit_line = right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2]\n",
    "    \n",
    "    xleft_low = left_fit_line - margin\n",
    "    xleft_high = left_fit_line + margin\n",
    "    xright_low = right_fit_line - margin\n",
    "    xright_high = right_fit_line + margin\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > xleft_low) & (nonzerox < xleft_high))\n",
    "    right_lane_inds = ((nonzerox > xright_low) & (nonzerox < xright_high))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_lane, right_lane = fit_polynomial(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    return left_lane, right_lane\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Lane():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n",
    "        self.center_dist = None\n",
    "\n",
    "def sanity_check(left_lane, right_lane):\n",
    "    if any(left_lane.current_fit / left.best_fit > 0.15):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "dist_pickle = pickle.load(open( \"camera_cal/wide_dist_pickle.pickle\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # Should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    binary_image = binary_filter(image)\n",
    "    \n",
    "    top_down_binary_warped, perspective_M_bin = persepctive_transform(binary_image, mtx, dist)\n",
    "    \n",
    "    left_lane, right_lane = fit_lane_lines(top_down_binary_warped)\n",
    "    \n",
    "    inv_warped_img = og_img_plot_lanes(binary_image, left_lane, right_lane)\n",
    "    \n",
    "    inv_warped_img = display_data(inv_warped_img, left_lane, right_lane)\n",
    "    \n",
    "    result = weighted_img(inv_warped_img, image, 1.0, 0.3, 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_with_lanes.mp4\n",
      "[MoviePy] Writing video project_video_with_lanes.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████▊   | 25/26 [00:05<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_with_lanes.mp4 \n",
      "\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "left_lane = Lane()\n",
    "right_lane = Lane()\n",
    "output = 'project_video_with_lanes.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,1)\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda image: process_image(image)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_with_lanes.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = 'challenge_video_with_result.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,5)\n",
    "# clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda image: process_image(image)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
